{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa964d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2023-07-25', 'time': '10:45:00', 'service_name': 'micro-service-t1', 'log_type': 'DEBUG'}, {'date': '2023-07-25', 'time': '10:30:00', 'service_name': 'micro-service-s3', 'log_type': 'ERROR'}, {'date': '2023-07-25', 'time': '10:15:00', 'service_name': 'micro-service-t2', 'log_type': 'INFO'}, {'date': '2023-07-25', 'time': '10:00:00', 'service_name': 'micro-service-s2', 'log_type': 'INFO'}, {'date': '2023-07-25', 'time': '10:00:00', 'service_name': 'micro-service-s4', 'log_type': 'WARN'}, {'date': '2023-07-25', 'time': '09:45:00', 'service_name': 'micro-service-r2', 'log_type': 'ERROR'}, {'date': '2023-07-25', 'time': '09:35:00', 'service_name': 'micro-service-r3', 'log_type': 'WARN'}, {'date': '2023-07-25', 'time': '09:30:00', 'service_name': 'micro-service-s1', 'log_type': 'DEBUG'}, {'date': '2023-07-25', 'time': '09:15:00', 'service_name': 'micro-service-r1', 'log_type': 'ERROR'}, {'date': '2023-07-25', 'time': '09:00:00', 'service_name': 'micro-service-q1', 'log_type': 'INFO'}]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "def consolidate_and_sort_logs(logs):\n",
    "    consolidated_logs = defaultdict(list)\n",
    "\n",
    "    # Iterate through input logs\n",
    "    for log_entry in logs:\n",
    "        for service, log_data in log_entry.items():\n",
    "            # Parse the date and time strings into a datetime object\n",
    "            log_datetime = datetime.strptime(f\"{log_data['date']} {log_data['time']}\", \"%a %B %d %Y %H:%M:%S\")\n",
    "\n",
    "            # Append the log entry to the corresponding service in consolidated_logs\n",
    "            consolidated_logs[service].append({\n",
    "                \"date\": log_datetime.strftime(\"%Y-%m-%d\"),\n",
    "                \"time\": log_datetime.strftime(\"%H:%M:%S\"),\n",
    "                \"service_name\": service,\n",
    "                \"log_type\": log_data[\"log_type\"]\n",
    "            })\n",
    "\n",
    "    # Flatten the dictionary and sort the log entries by date and time in descending order\n",
    "    sorted_logs = sorted([entry for log_entries in consolidated_logs.values() for entry in log_entries],\n",
    "                         key=lambda x: (x[\"date\"], x[\"time\"]), reverse=True)\n",
    "\n",
    "    return sorted_logs\n",
    "\n",
    "# Test Case 1\n",
    "input1 = [\n",
    "    {\n",
    "        \"micro-service-q1\": {\"log_type\": \"INFO\", \"date\": \"Wed July 25 2023\", \"time\": \"09:00:00\"},\n",
    "        \"micro-service-r1\": {\"log_type\": \"ERROR\", \"date\": \"Wed July 25 2023\", \"time\": \"09:15:00\"},\n",
    "        \"micro-service-s1\": {\"log_type\": \"DEBUG\", \"date\": \"Wed July 25 2023\", \"time\": \"09:30:00\"},\n",
    "    },\n",
    "    {\n",
    "        \"micro-service-r2\": {\"log_type\": \"ERROR\", \"date\": \"Wed July 25 2023\", \"time\": \"09:45:00\"},\n",
    "        \"micro-service-s2\": {\"log_type\": \"INFO\", \"date\": \"Wed July 25 2023\", \"time\": \"10:00:00\"},\n",
    "        \"micro-service-t1\": {\"log_type\": \"DEBUG\", \"date\": \"Wed July 25 2023\", \"time\": \"10:45:00\"},\n",
    "        \"micro-service-r3\": {\"log_type\": \"WARN\", \"date\": \"Wed July 25 2023\", \"time\": \"09:35:00\"},\n",
    "    },\n",
    "    {\n",
    "        \"micro-service-s3\": {\"log_type\": \"ERROR\", \"date\": \"Wed July 25 2023\", \"time\": \"10:30:00\"},\n",
    "        \"micro-service-t2\": {\"log_type\": \"INFO\", \"date\": \"Wed July 25 2023\", \"time\": \"10:15:00\"},\n",
    "        \"micro-service-s4\": {\"log_type\": \"WARN\", \"date\": \"Wed July 25 2023\", \"time\": \"10:00:00\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "output1 = consolidate_and_sort_logs(input1)\n",
    "print(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ff50af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2023-07-25', 'time': '14:50:00', 'service_name': 'micro-service-p1', 'log_type': 'DEBUG'}, {'date': '2023-07-25', 'time': '14:40:00', 'service_name': 'micro-service-o1', 'log_type': 'INFO'}, {'date': '2023-07-25', 'time': '14:30:00', 'service_name': 'micro-service-n1', 'log_type': 'ERROR'}, {'date': '2023-07-25', 'time': '14:00:00', 'service_name': 'micro-service-m1', 'log_type': 'INFO'}]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "def consolidate_and_sort_logs(logs):\n",
    "    consolidated_logs = defaultdict(list)\n",
    "\n",
    "    # Iterate through input logs\n",
    "    for log_entry in logs:\n",
    "        for service, log_data in log_entry.items():\n",
    "            # Split the date and time parts\n",
    "            date_parts = log_data['date'].split()\n",
    "            time_parts = log_data['time'].split()\n",
    "\n",
    "            # Extract the timezone offset part\n",
    "            timezone_offset = time_parts[-1]\n",
    "            time_parts = time_parts[:-1]\n",
    "\n",
    "            # Combine date and time parts, and add timezone offset\n",
    "            log_datetime_str = ' '.join(date_parts + time_parts + [timezone_offset])\n",
    "\n",
    "            # Parse the log timestamp including the timezone offset\n",
    "            log_datetime = datetime.strptime(log_datetime_str, \"%a %b %d %Y %H:%M:%S %Z%z\")\n",
    "\n",
    "            # Append the log entry to the corresponding service in consolidated_logs\n",
    "            consolidated_logs[service].append({\n",
    "                \"date\": log_datetime.strftime(\"%Y-%m-%d\"),\n",
    "                \"time\": log_datetime.strftime(\"%H:%M:%S\"),\n",
    "                \"service_name\": service,\n",
    "                \"log_type\": log_data[\"log_type\"]\n",
    "            })\n",
    "\n",
    "     # Flatten the dictionary and sort the log entries by date and time in descending order\n",
    "    sorted_logs = sorted([entry for log_entries in consolidated_logs.values() for entry in log_entries],\n",
    "                         key=lambda x: (x[\"date\"], x[\"time\"]), reverse=True)\n",
    "\n",
    "    return sorted_logs\n",
    "\n",
    "# Test Case 2\n",
    "input2 = [ \n",
    "{\n",
    "\"micro-service-m1\": {\"log_type\": \"INFO\",\"date\": \"Wed Jul 25 2023\", \"time\":\"14:00:00 GMT+0530\"}, \n",
    "\"micro-service-n1\": {\"log_type\": \"ERROR\",\"date\": \"Wed Jul 25 2023\", \"time\":\"14:10:00 GMT+0530\"}, \n",
    "\"micro-service-o1\": {\"log_type\": \"DEBUG\",\"date\": \"Wed Jul 25 2023\", \"time\":\"14:20:00 GMT+0530\"}, \n",
    "\"micro-service-n1\": {\"log_type\": \"ERROR\",\"date\": \"Wed Jul 25 2023\", \"time\":\"14:30:00 GMT+0530\"}, \n",
    "\"micro-service-o1\": {\"log_type\": \"INFO\",\"date\": \"Wed Jul 25 2023\", \"time\":\"14:40:00 GMT+0530\"}, \n",
    "\"micro-service-p1\": {\"log_type\": \"DEBUG\",\"date\": \"Wed Jul 25 2023\", \"time\":\"14:50:00 GMT+0530\"} \n",
    "} \n",
    "] \n",
    "\n",
    "output2 = consolidate_and_sort_logs(input2)\n",
    "print(output2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac839b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'date': '2023-07-25', 'time': '10:00:00', 'service_name': 'micro-service-s1', 'log_type': 'INFO'}, {'date': '2023-07-15', 'time': '10:00:00', 'service_name': 'micro-service-s2', 'log_type': 'INFO'}]\n"
     ]
    }
   ],
   "source": [
    "input3 = [\n",
    "    {\n",
    "        \"micro-service-s1\": {\"log_type\": \"INFO\", \"date\": \"Wed Jul 25 2023\", \"time\": \"10:00:00 GMT+0530\"},\n",
    "        \"micro-service-s2\": {\"log_type\": \"INFO\", \"date\": \"Wed Jul 15 2023\", \"time\": \"10:00:00 GMT+0530\"},\n",
    "    }\n",
    "]\n",
    "\n",
    "output3 = consolidate_and_sort_logs(input3)\n",
    "\n",
    "print(output3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0b34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
